{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7105282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader,TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39deeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a100304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello. I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How about you? How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 41, 'total_tokens': 94, 'completion_time': 0.116392799, 'prompt_time': 0.0020401, 'queue_time': 0.052654596, 'total_time': 0.118432899}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--127549db-9837-41fa-ac1e-f40d77068a27-0', usage_metadata={'input_tokens': 41, 'output_tokens': 53, 'total_tokens': 94})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    api_key=groq_api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4470ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1152.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Climate Change\n",
      "Climate change refers to long-term shifts in temperatures and weather patterns, largely driven by human activities such as burning fossil fuels. These activities increase greenhouse gas concentrations in the atmosphere, trapping heat and altering global climates. Consequences include rising sea levels, extreme weather events, and biodiversity loss.\n",
      "\n",
      "Space Exploration\n",
      "Humanity’s interest in space has evolved from simple stargazing to landing rovers on Mars. Organizations like NASA and private companies like SpaceX are pushing boundaries by exploring planets, planning moon bases, and even contemplating missions to Jupiter's moons. Space exploration drives technological innovation and inspires global collaboration.\n",
      "\n",
      "Artificial Intelligence Ethics\n",
      "As AI systems become more capable, ethical concerns arise about their usage, decision-making, and transparency. Issues like algorithmic bias, lack of accountability, and potential misuse in surveillance or warfare raise important moral questions. A multidisciplinary approach is required to ensure AI aligns with societal values.\n",
      "\n",
      "Globalization\n",
      "Globalization describes the process by which businesses, cultures, and technologies become integrated across borders. While it facilitates economic growth and cultural exchange, it also leads to labor exploitation, environmental damage, and loss of local traditions. Balancing its benefits and drawbacks is a major global challenge.\n",
      "\n",
      "Cryptocurrency\n",
      "Cryptocurrencies are decentralized digital assets that use blockchain technology for secure transactions. Bitcoin, Ethereum, and similar currencies promise financial autonomy and lower transaction fees but face issues like regulatory uncertainty, market volatility, and environmental concerns due to high energy consumption in mining.' metadata={'source': '../data/practical_rag_data/data1.txt'}\n",
      "page_content='Climate Change\n",
      "Climate change refers to long-term shifts in temperatures and weather patterns, largely driven by human activities such as burning fossil fuels. These activities increase greenhouse gas concentrations in the atmosphere, trapping heat and altering global climates. Consequences include rising sea levels, extreme weather events, and biodiversity loss.' metadata={'source': '../data/practical_rag_data/data1.txt'} page_content='Space Exploration\n",
      "Humanity’s interest in space has evolved from simple stargazing to landing rovers on Mars. Organizations like NASA and private companies like SpaceX are pushing boundaries by exploring planets, planning moon bases, and even contemplating missions to Jupiter's moons. Space exploration drives technological innovation and inspires global collaboration.' metadata={'source': '../data/practical_rag_data/data1.txt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directoryLoader = DirectoryLoader(\n",
    "    path=\"../data/practical_rag_data/\",\n",
    "    loader_cls=TextLoader,\n",
    "    show_progress=True,\n",
    "    glob=\"**/*.txt\"\n",
    ")\n",
    "\n",
    "data=directoryLoader.load()\n",
    "print(data[0])\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,   \n",
    ")\n",
    "\n",
    "chunks=text_splitter.split_documents(data)\n",
    "print(chunks[0],chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c878d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c303989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")\n",
    "# Creating Chroma DB\n",
    "\n",
    "db=Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=hf,\n",
    "    persist_directory=\"../rag_db\",\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "retriever=db.as_retriever(\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Initialize LLM + Retriever\n",
    "# ----------------------------\n",
    "\n",
    "# Make sure you have your API key set:\n",
    "# export OPENAI_API_KEY=\"sk-....\"\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# Chat model (adjust model name as you like)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Create a tiny in-memory knowledge base\n",
    "docs = [\n",
    "    \"Machine learning (ML) is a subfield of artificial intelligence focused on building systems that learn from data.\",\n",
    "    \"Common types of machine learning include supervised learning, unsupervised learning, and reinforcement learning.\",\n",
    "    \"Supervised learning uses labeled data to learn a mapping from inputs to outputs.\",\n",
    "    \"Unsupervised learning finds patterns or structure in unlabeled data (e.g., clustering, dimensionality reduction).\",\n",
    "    \"Reinforcement learning trains an agent to act in an environment by maximizing cumulative reward.\"\n",
    "]\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_texts(docs, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# -------------------------------------\n",
    "# 2) Build the history-aware retriever\n",
    "# -------------------------------------\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt=contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# -------------------------------------\n",
    "# 3) Build the QA chain (stuff strategy)\n",
    "# -------------------------------------\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "# -------------------------------------\n",
    "# 4) Compose the full conversational RAG\n",
    "# -------------------------------------\n",
    "\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    retriever=history_aware_retriever,\n",
    "    combine_docs_chain=question_answer_chain\n",
    ")\n",
    "\n",
    "print(\"✅ Conversational RAG chain created!\\n\")\n",
    "\n",
    "# -------------------------------------\n",
    "# 5) Demo run\n",
    "# -------------------------------------\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "# First question\n",
    "result1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What is machine learning?\"\n",
    "})\n",
    "\n",
    "print(\"Q1: What is machine learning?\")\n",
    "print(\"A1:\", result1.get(\"answer\", result1))\n",
    "print()\n",
    "\n",
    "# Update chat history\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What is machine learning?\"),\n",
    "    AIMessage(content=result1.get(\"answer\", \"\")),\n",
    "])\n",
    "\n",
    "# Follow-up question (history-aware)\n",
    "result2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What are its main types?\"\n",
    "})\n",
    "\n",
    "print(\"Q2: What are its main types?\")\n",
    "print(\"A2:\", result2.get(\"answer\", result2))\n",
    "print()\n",
    "\n",
    "# (Optional) Ask another follow-up to see reformulation in action\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What are its main types?\"),\n",
    "    AIMessage(content=result2.get(\"answer\", \"\")),\n",
    "])\n",
    "\n",
    "result3 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Give me one-sentence definitions for each.\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319f77c",
   "metadata": {},
   "source": [
    "## CONVERSATIONAL MEMORY USING RUNNABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-core langchain-community langchain-openai faiss-cpu tiktoken\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# --- base LLM & retriever ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "docs = [\n",
    "    \"Machine learning is a subfield of AI that learns patterns from data.\",\n",
    "    \"The main types of ML are supervised, unsupervised, and reinforcement learning.\",\n",
    "]\n",
    "vs = FAISS.from_texts(docs, emb)\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# --- contextualizer ---\n",
    "contextualize_q_system = \"\"\"Given chat history + latest user Q, rewrite it as a standalone question.\n",
    "Don't answer; just return the rewritten question (or the original if already standalone).\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm, retriever=retriever, prompt=contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# --- QA chain ---\n",
    "qa_system = \"\"\"You are an assistant for QA. Use retrieved context only.\n",
    "If unknown, say you don't know. Max three sentences.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "qa_chain = create_stuff_documents_chain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "# --- Conversational RAG ---\n",
    "rag = create_retrieval_chain(history_aware_retriever, qa_chain)\n",
    "\n",
    "# --- Add memory (no more manual chat_history handling) ---\n",
    "store = {}  # session_id -> InMemoryChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "rag_with_memory = RunnableWithMessageHistory(\n",
    "    rag,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",   # typical key produced by create_retrieval_chain\n",
    ")\n",
    "\n",
    "# --- Use it: just pass a session_id in config ---\n",
    "cfg = {\"configurable\": {\"session_id\": \"user-42\"}}\n",
    "\n",
    "print(rag_with_memory.invoke({\"input\": \"What is machine learning?\"}, cfg)[\"answer\"])\n",
    "print(rag_with_memory.invoke({\"input\": \"What are its main types?\"}, cfg)[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
